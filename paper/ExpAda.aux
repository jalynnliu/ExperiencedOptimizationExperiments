\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{he2016deep,lecun2015deep,long2015fully,ronneberger2015u}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {title}{Only Image cosine Embedding for Few-shot learning}{1}{chapter.1}}
\@writefile{toc}{\authcount {3}}
\@writefile{toc}{\contentsline {author}{Songyi Gao \and Zelin Liu \unskip {}  \and \unskip \ \ignorespaces  Weijie Shen}{1}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}}
\citation{mishra2017simple}
\citation{qin2019rethink}
\citation{finn2017model,nichol2018first}
\citation{vinyals2016matching}
\citation{snell2017prototypical}
\citation{sung2018learning}
\citation{gidaris2018dynamic}
\citation{salimans2016weight}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Pre-Training Phase}{3}{subsection.1.3.1}}
\citation{salimans2016weight}
\citation{li2019learning}
\newlabel{equ1}{{1}{4}{Pre-Training Phase}{equation.1.3.1}{}}
\newlabel{alg1}{{1}{5}{Pre-Training Phase}{algocfline.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Training Process}}{5}{algocf.1}}
\newlabel{alg2}{{2}{5}{Pre-Training Phase}{algocfline.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Train special classifier}}{5}{algocf.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Fintune Phase}{5}{subsection.1.3.2}}
\citation{vinyals2016matching}
\citation{mishra2017simple,qin2019rethink,finn2017model,vinyals2016matching,snell2017prototypical}
\citation{russakovsky2015imagenet}
\citation{chen2019closer}
\citation{wah2011caltech}
\citation{ioffe2015batch}
\citation{chen2019closer,cheny2019multi,sun2018meta}
\citation{he2016deep}
\citation{chen2019closer}
\citation{chen2019closer}
\citation{chen2019closer}
\citation{chen2019closer}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental}{6}{section.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset}{6}{subsection.1.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Implementation details}{6}{subsection.1.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Experiments on MiniImagenet and CUB-200 dataset}{6}{subsection.1.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{Expermiments on minimagent:}{6}{section*.2}}
\citation{cheny2019multi}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Few-shot classification accuracy on MiniImageNet. We validate our approach on the MiniImageNet dataset using three backbones(Conv4, ResNet10 and ResNet18). We use 84*84 input size when the backbone is Conv4, and use 224*224 input size in ResNet backbone. To be fair, some expermiments results come from\nobreakspace  {}\cite  {chen2019closer}, and we use the same image size training data with the same backbone. We use the approach proposed in\nobreakspace  {}\cite  {chen2019closer} as a baseline approach. The superscript “*” indicates that we use base and validation data for model training with a total of 80 classes.}}{7}{table.1.1}}
\newlabel{tab1}{{1}{7}{Few-shot classification accuracy on MiniImageNet. We validate our approach on the MiniImageNet dataset using three backbones(Conv4, ResNet10 and ResNet18). We use 84*84 input size when the backbone is Conv4, and use 224*224 input size in ResNet backbone. To be fair, some expermiments results come from~\cite {chen2019closer}, and we use the same image size training data with the same backbone. We use the approach proposed in~\cite {chen2019closer} as a baseline approach. The superscript “*” indicates that we use base and validation data for model training with a total of 80 classes}{table.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Expermiments on CUB-200 dataset:}{7}{section*.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Few-shot classification results on CUB-200 dataset. ResNet-18 dosen't have feature enhancement; As the name suggests, ResNet-18+Gaussian Noise uses Gaussian Noise for feature enhancement; Resnet-18+DualTriNet uses the semantic information contained in the class name for feature enhancement.}}{8}{table.1.2}}
\newlabel{tab2}{{2}{8}{Few-shot classification results on CUB-200 dataset. ResNet-18 dosen't have feature enhancement; As the name suggests, ResNet-18+Gaussian Noise uses Gaussian Noise for feature enhancement; Resnet-18+DualTriNet uses the semantic information contained in the class name for feature enhancement}{table.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Experiment with different K values on MiniImageNet:}{8}{section*.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) shows the model test results using only base set training data;(b) shows the result of using base and validation data for model training with a total of 80 classes.}}{8}{figure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{8}{figure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{8}{figure.1.1}}
\newlabel{fig1}{{1}{8}{(a) shows the model test results using only base set training data;(b) shows the result of using base and validation data for model training with a total of 80 classes}{figure.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Experiment with different $N$ values on MiniImageNet:}{8}{section*.5}}
\citation{maaten2008visualizing}
\citation{zhang2017mixup}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces N-way 5-shot experiment. All methods use ResNet18 as backbone. The MatchingNet, ProtoNet and RelationNet use the 5-way 5-shot task setting in train phase.}}{9}{table.1.3}}
\newlabel{tab3}{{3}{9}{N-way 5-shot experiment. All methods use ResNet18 as backbone. The MatchingNet, ProtoNet and RelationNet use the 5-way 5-shot task setting in train phase}{table.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature vectors analysis:}{9}{section*.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Extended experiment}{9}{subsection.1.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{Use mixup to augment the train data:}{9}{section*.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (a), (b), (c) and (d) randomly select 5, 10, 15 and 20 classes on the novel dataset of MiniImageNet, and each class randomly sampled 50 samples for feature visualization.}}{10}{figure.1.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{10}{figure.1.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{10}{figure.1.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{10}{figure.1.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{10}{figure.1.2}}
\newlabel{fig2}{{2}{10}{(a), (b), (c) and (d) randomly select 5, 10, 15 and 20 classes on the novel dataset of MiniImageNet, and each class randomly sampled 50 samples for feature visualization}{figure.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces extended experiment. The task setting is 5-way 5-shot and backone is ResNet-18.}}{10}{table.1.4}}
\newlabel{tab4}{{4}{10}{extended experiment. The task setting is 5-way 5-shot and backone is ResNet-18}{table.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Few-shot classification accuracy vs. remove the dimension of the feature. The task setting is 5-way 5-shot and backone is ResNet-18.we average the results over 10000 experiments.}}{11}{figure.1.3}}
\newlabel{fig3}{{3}{11}{Few-shot classification accuracy vs. remove the dimension of the feature. The task setting is 5-way 5-shot and backone is ResNet-18.we average the results over 10000 experiments}{figure.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Delete some features:}{11}{section*.8}}
\@writefile{toc}{\contentsline {subsubsection}{Don’t use the weights-biased softmax in the fintune phase:}{11}{section*.9}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{11}{section.1.5}}
\bibstyle{splncs04}
\bibdata{OICEref}
\bibcite{chen2019closer}{1}
\bibcite{cheny2019multi}{2}
\bibcite{finn2017model}{3}
\bibcite{gidaris2018dynamic}{4}
\bibcite{he2016deep}{5}
\bibcite{ioffe2015batch}{6}
\bibcite{lecun2015deep}{7}
\bibcite{li2019learning}{8}
\bibcite{long2015fully}{9}
\bibcite{maaten2008visualizing}{10}
\bibcite{mishra2017simple}{11}
\bibcite{nichol2018first}{12}
\bibcite{qin2019rethink}{13}
\bibcite{ronneberger2015u}{14}
\bibcite{russakovsky2015imagenet}{15}
\bibcite{salimans2016weight}{16}
\bibcite{snell2017prototypical}{17}
\bibcite{sun2018meta}{18}
\bibcite{sung2018learning}{19}
\bibcite{vinyals2016matching}{20}
\bibcite{wah2011caltech}{21}
\bibcite{zhang2017mixup}{22}
